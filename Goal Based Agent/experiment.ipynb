{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f362f1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All OK!!\n"
     ]
    }
   ],
   "source": [
    "print(\"All OK!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c402edf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import initialize_agent, Tool, AgentType\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from dotenv import load_dotenv\n",
    "import re, os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f677030",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30feda12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000029E3F647EE0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000029E42ACFC10>, root_client=<openai.OpenAI object at 0x0000029E3F647D00>, root_async_client=<openai.AsyncOpenAI object at 0x0000029E42ACFB80>, temperature=0.2, model_kwargs={}, openai_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08d9db6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASIF\\AppData\\Local\\Temp\\ipykernel_8452\\121037554.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory=ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "memory=ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ada83226",
   "metadata": {},
   "outputs": [],
   "source": [
    "application_info={\n",
    "    \"name\":None,\n",
    "    \"email\":None,\n",
    "    \"skills\":None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f523e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_application_info(text):\n",
    "    name_match=re.search(r\"(?:my name is|i am|name)\\s+([A-Z][a-z]+(?:\\s+[A-Z][a-z]+)*)\", text, re.IGNORECASE)\n",
    "    email_match=re.search(r\"\\b[\\w.-]+@[\\w.-]+\\.\\w+\\b\", text)\n",
    "    skill_match=re.search(r\"(?:skills are|i know | i can use|skills|Skills)\\s+(.*)\", text, re.IGNORECASE)\n",
    "    \n",
    "    response=[]\n",
    "    \n",
    "    if name_match:\n",
    "        application_info[\"name\"]=name_match.group(1).title()\n",
    "        response.append(\"Name Saved.\")\n",
    "    if email_match:\n",
    "        application_info[\"email\"]=email_match.group(0)\n",
    "        response.append(\"Email Saved.\")\n",
    "    if skill_match:\n",
    "        application_info[\"skills\"]=skill_match.group(1).strip()\n",
    "        response.append(\"Skills Saved.\")\n",
    "    \n",
    "    if not any([name_match, email_match, skill_match]):\n",
    "        return \"I could`nt extract any Info, Could you please provide your name, email or skills to complete application process\"\n",
    "    else:\n",
    "        return \" \".join(response) + \" Let me check what else I need\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb9d411",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_application_goal(_=None):\n",
    "    if all(application_info.values()):\n",
    "        return f\"You are ready! Name : {application_info['name']}, Email : {application_info['email']}, Skills : {application_info['skills']}\"\n",
    "    else:\n",
    "        missing=[k for k,v in application_info.items() if not v]\n",
    "        return f\" Still Need {','.join(missing)}. please ask the user to provide this.\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e72207f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating custom tools\n",
    "\n",
    "tools=[\n",
    "    Tool(\n",
    "        name=\"extract_application_info\",\n",
    "        func=extract_application_info,\n",
    "        description=\"use this function to extract name,email and skills from the user`s message/text.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"check_application_goal\",\n",
    "        func=check_application_goal,\n",
    "        description=\"Check if name, email and skills are provided.If not, tell the user what is missing.\",\n",
    "        return_direct=True # --important!\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68f1b741",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt=\"\"\"\n",
    "You are a helpful job application assistant.\n",
    "Your goal is to collect user`s name, email and skills.\n",
    "use the tools provided to extract this information and check wether all required data is collected.\n",
    "Once everything is collected, inform the user that the application info is complete and stop. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9c47441",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASIF\\AppData\\Local\\Temp\\ipykernel_8452\\2515223582.py:2: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent=initialize_agent(\n"
     ]
    }
   ],
   "source": [
    "#initialize agent\n",
    "agent=initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    agent_kwargs={\"system_message\":system_prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34ea556c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(memory=ConversationBufferMemory(chat_memory=InMemoryChatMessageHistory(messages=[]), return_messages=True, memory_key='chat_history'), verbose=True, tags=['chat-conversational-react-description'], agent=ConversationalChatAgent(llm_chain=LLMChain(verbose=False, prompt=ChatPromptTemplate(input_variables=['agent_scratchpad', 'chat_history', 'input'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000029E405A9D80>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000029E405A9D80>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='\\nYou are a helpful job application assistant.\\nYour goal is to collect user`s name, email and skills.\\nuse the tools provided to extract this information and check wether all required data is collected.\\nOnce everything is collected, inform the user that the application info is complete and stop. \\n'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='TOOLS\\n------\\nAssistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\\n\\n> extract_application_info: use this function to extract name,email and skills from the user`s message/text.\\n> check_application_goal: Check if name, email and skills are provided.If not, tell the user what is missing.\\n\\nRESPONSE FORMAT INSTRUCTIONS\\n----------------------------\\n\\nWhen responding to me, please output a response in one of two formats:\\n\\n**Option 1:**\\nUse this if you want the human to use a tool.\\nMarkdown code snippet formatted in the following schema:\\n\\n```json\\n{{\\n    \"action\": string, \\\\\\\\ The action to take. Must be one of extract_application_info, check_application_goal\\n    \"action_input\": string \\\\\\\\ The input to the action\\n}}\\n```\\n\\n**Option #2:**\\nUse this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\\n\\n```json\\n{{\\n    \"action\": \"Final Answer\",\\n    \"action_input\": string \\\\\\\\ You should put what you want to return to use here\\n}}\\n```\\n\\nUSER\\'S INPUT\\n--------------------\\nHere is the user\\'s input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\\n\\n{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')]), llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000029E3F647EE0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000029E42ACFC10>, root_client=<openai.OpenAI object at 0x0000029E3F647D00>, root_async_client=<openai.AsyncOpenAI object at 0x0000029E42ACFB80>, temperature=0.2, model_kwargs={}, openai_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}), output_parser=ConvoOutputParser(), allowed_tools=['extract_application_info', 'check_application_goal'], template_tool_response=\"TOOL RESPONSE:\\n---------------------\\n{observation}\\n\\nUSER'S INPUT\\n--------------------\\n\\nOkay, so what is the response to my last comment? If using information obtained from the tools you must mention it explicitly without mentioning the tool names - I have forgotten all TOOL RESPONSES! Remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else.\"), tools=[Tool(name='extract_application_info', description='use this function to extract name,email and skills from the user`s message/text.', func=<function extract_application_info at 0x0000029E3E466680>), Tool(name='check_application_goal', description='Check if name, email and skills are provided.If not, tell the user what is missing.', return_direct=True, func=<function check_application_goal at 0x0000029E3E467D90>)])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5694f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat Loop\n",
    "print(\"Hi! I am your job application assistant. Please tell me your Name, Email and Skills.\")\n",
    "\n",
    "while True:\n",
    "    user_input=input(\"You: \")\n",
    "    if user_input.lower() in [\"exit\",\"quit\"]:\n",
    "        print(\"Bye ! Good Luck.\")\n",
    "        break\n",
    "    response=agent.invoke({\"input\":user_input})\n",
    "    print(\"Bot: \", response[\"output\"])\n",
    "    \n",
    "    #if goal achieved, stop\n",
    "    if \"You are ready!\" in response[\"output\"].lower():\n",
    "        print(\"Application info completed\")\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26424f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    user_input=input(\"You: \")\n",
    "    if user_input.lower() in [\"exit\",\"quit\"]:\n",
    "        print(\"Bye ! Good Luck.\")\n",
    "        break\n",
    "    response=agent.invoke({\"input\":user_input})\n",
    "    print(\"Bot: \", response[\"output\"])\n",
    "    \n",
    "    #if goal achieved, stop\n",
    "    if \"You are ready!\" in response[\"output\"].lower():\n",
    "        print(\"Application info completed\")\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GBA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
